https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-4-human-in-the-loop

## Part 5: 상태 커스텀하기
지금까지는 메시지 목록 하나만을 포함하는 단순한 상태에 의존해 왔습니다. 이처럼 간단한 상태만으로도 많은 작업을 수행할 수 있지만, 메시지 리스트에만 의존하지 않고 더 복잡한 동작을 정의하고 싶다면 상태에 추가 필드를 넣을 수 있습니다.

여기서는 새로운 시나리오를 보여드리겠습니다. 챗봇이 **검색 도구**를 사용해 특정 정보를 찾아내고, 그 결과를 사람에게 검토하기 위해서 전달하는 상황입니다. 예를 들어, 챗봇이 어떤 인물의 생일을 조사하도록 해보겠습니다. 이를 위해 상태에 `name`과 `birthday` 키를 추가할 것입니다.
``` python
from typing import Annotated

from typing_extensions import TypedDict

from langgraph.graph.message import add_messages


class State(TypedDict):
    messages: Annotated[list, add_messages]
    name: str #
    birthday: str #
```

이 정보를 상태에 추가하면, 다른 그래프 노드들(예: 정보를 저장하거나 처리하는 하위 노드)뿐만 아니라 그래프의 영속성 계층에서도 쉽게 접근할 수 있게 됩니다.

여기서는 `human_assistance` 도구 내부에서 state key들을 채워넣을 것입니다. 이렇게 하면 정보가 상태에 저장되기 전에 인간이 이를 검토할 수 있게 됩니다. 이번에도 `Command`를 사용할 것인데, 이번에는 도구 내부에서 **상태 업데이트를 수행**하는 데에 사용됩니다. `Command`의 다양한 유즈케이스에 대해서는 [여기](https://langchain-ai.github.io/langgraph/concepts/low_level/#using-inside-tools)에서 더 자세히 알아볼 수 있습니다.
``` python
from langchain_core.messages import ToolMessage
from langchain_core.tools import InjectedToolCallId, tool

from langgraph.types import Command, interrupt


@tool
# 상태 업데이트를 위한 ToolMessage를 생성할 때는 일반적으로
# 해당 tool call의 ID가 필요하다는 점에 유의하세요.
# LangChain의 InjectedToolCallId를 사용하면,
# 이 인자를 도구의 스키마에서 모델에게 노출하지 않도록 지정할 수 있습니다.
def human_assistance(
    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]
) -> str:
    """Request assistance from a human."""
    human_response = interrupt(
        {
            "question": "Is this correct?",
            "name": name,
            "birthday": birthday,
        },
    )
    # 만약 정보가 정확하다면, 이전의 상태를 업데이트합니다.
    if human_response.get("correct", "").lower().startswith("y"):
        verified_name = name
        verified_birthday = birthday
        response = "Correct"
    # 그렇지 않다면, 사람 리뷰어로부터 정보를 받습니다.
    else:
        verified_name = human_response.get("name", name)
        verified_birthday = human_response.get("birthday", birthday)
        response = f"Made a correction: {human_response}"

    # 툴 안에서 ToolMessage를 사용하여 상태를 명시적으로 업데이트합니다. 
    state_update = {
        "name": verified_name,
        "birthday": verified_birthday,
        "messages": [ToolMessage(response, tool_call_id=tool_call_id)],
    }

    # 상태를 업데이트하기 위해 툴 안의 Command 객체를 리턴합니다.
    return Command(update=state_update)
```

그 외에는, 그래프의 나머지 부분은 동일합니다.
``` python
from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode, tools_condition


tool = TavilySearchResults(max_results=2)
tools = [tool, human_assistance]
llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    message = llm_with_tools.invoke(state["messages"])
    assert len(message.tool_calls) <= 1
    return {"messages": [message]}


graph_builder = StateGraph(State)
graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=tools)
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")

memory = MemorySaver()
graph = graph_builder.compile(checkpointer=memory)
```
