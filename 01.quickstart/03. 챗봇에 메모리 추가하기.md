## Part 3: 챗봇에 메모리 추가하기
챗봇은 사용자 질문에 tool을 이용하여 답할 수 있으나, 이전의 상호작용의 컨텍스트를 기억하지 못합니다. 이것은 일관성 있는 multi-turn 대화를 수행하는 능력을 제한합니다.

랭그래프는 `persistent checkpointing`을 통해 이 문제를 해결할 수 있습니다. 그래프를 컴파일할 때 체크포인터를 제공하고, 그래프를 호출할 때 `thread_id`를 제공하면, LangGraph는 각 단계 이후에 상태를 자동으로 저장합니다. 동일한 `thread_id`를 사용하여 그래프를 다시 호출하면, 그래프는 저장된 상태를 불러와 챗봇이 중단된 지점부터 다시 이어서 대화를 진행할 수 있습니다. 

단순한 채팅 메모리보다 더 파워풀한 `checkpointing`은 조금 뒤에 살펴볼 것이며, 오류 복구, 인간의 검토가 포함된 워크플로우, 과거 상태로 돌아가는 상호작용 등 언제든지 복잡한 상태를 저장하고 다시 불러올 수 있게 해줍니다. 하지만, 앞서 나가기 전에 우선 multi-turn 대화를 가능하게 하기 위해서 checkpointing을 추가해봅시다.

`MemorySaver` checkpointer를 만들어 봅시다.
``` python
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
```
API Reference: [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)

**Notice** 간편한 튜토리얼 진행을 위해 인메모리 체크포인터를 사용중입니다(모든 것을 메모리에 저장합니다.). 프로덕션 어플리케이션이라면, 이것을 `SqliteSaver`나 `PostgreSaver`로 바꾸어 데이터베이스와 연결하는 것이 좋습니다.

다음은 그래프를 정의해 봅시다. 이미 `BasicToolNode`를 만들었으니, 우리는 그것을 랭그래프의 prebuilt된 `ToolNode`와 `tools_condition`으로 변경하고, 이들은 API를 병렬로 실행하는 등 유용한 기능들을 제공하기 때문입니다. 그 외에는 아래 내용은 모두 Part2에서 복사해온 것들입니다.
``` python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
# Any time a tool is called, we return to the chatbot to decide the next step
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
```
API Reference: [ChatAnthropic](https://python.langchain.com/api_reference/anthropic/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html) | [TavilySearchResults](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html) | [BaseMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.base.BaseMessage.html)
| [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode)
| [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.tools_condition)


마침내, checkpointer가 추가된 그래프를 컴파일하였습니다.
``` python
graph = graph_builder.compile(checkpointer=memory)
```
그래프의 연결 구조는 Part2와 같습니다. 각 노드를 거치며 그래프가 작동하는 동안 상태(State)를 체크포인트로 저장하는 것뿐입니다.
``` python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # This requires some extra dependencies and is optional
    pass
```

![Image](https://github.com/user-attachments/assets/7cf31980-9629-4e19-a6f9-ca2457b1af8c)

이제, 만든 봇과 상호작용할 수 있게 되었습니다. 먼저, 이 대화의 key를 사용하여 스레드를 가져오세요.
``` python
config = {"configurable": {"thread_id": "1"}}
```
그 다음, 챗봇을 호출하세요.
``` python
user_input = "Hi there! My name is Will."

# The config is the **second positional argument** to stream() or invoke()!
events = graph.stream(
    {"messages": [{"role": "user", "content": user_input}]},
    config, # <--
    stream_mode="values",
)
for event in events:
    event["messages"][-1].pretty_print()
```
```
================================[1m Human Message [0m=================================

Hi there! My name is Will.
==================================[1m Ai Message [0m==================================

Hello Will! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to know or discuss?
```

**Note**: 구성은 그래프를 호출할 때 두 번째 위치 인자로 제공되었습니다. 중요한 점은, 이것이 그래프 입력값(`{'messages': []}`) 안에 중첩되어 있지 않다는 것입니다.

뒤이어 다음 질문을 해봅시다: 당신의 이름을 기억하고 있는지 확인해보세요.
``` python
user_input = "Remember my name?"

# The config is the **second positional argument** to stream() or invoke()!
events = graph.stream(
    {"messages": [{"role": "user", "content": user_input}]},
    config,
    stream_mode="values",
)
for event in events:
    event["messages"][-1].pretty_print()
```
```
================================[1m Human Message [0m=================================

Remember my name?
==================================[1m Ai Message [0m==================================

Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you'd like to talk about or any questions you have? I'm here to help with a wide range of topics or tasks.
```

**Notice** 메모리를 위해 외부 리스트를 사용하지 않고 있다는 점에 주목하세요. 이 모든 것은 체크포인터가 처리하고 있습니다! 무슨 일이 일어났는지 확인하려면 이 [LangSmith](https://smith.langchain.com/public/29ba22b5-6d40-4fbe-8d27-b369e3329c84/r) 추적에서 전체 실행 과정을 살펴볼 수 있습니다.

![Image](https://github.com/user-attachments/assets/383f8c3a-3a48-403b-9547-5be1e329b991)

저를 못믿으시겠나요? 그렇다면 다른 구성을 시도해보세요.
``` python
# The only difference is we change the `thread_id` here to "2" instead of "1"
events = graph.stream(
    {"messages": [{"role": "user", "content": user_input}]},
    {"configurable": {"thread_id": "2"}}, # 1 -> 2로 스레드 번호 변경
    stream_mode="values",
)
for event in events:
    event["messages"][-1].pretty_print()
```
```
================================[1m Human Message [0m=================================

Remember my name?
==================================[1m Ai Message [0m==================================

I apologize, but I don't have any previous context or memory of your name. As an AI assistant, I don't retain information from past conversations. Each interaction starts fresh. Could you please tell me your name so I can address you properly in this conversation?
```

**Notice** config의 `thread_id`만 바뀌었습니다. [LangSmith trace](https://smith.langchain.com/public/51a62351-2f0a-4058-91cc-9996c5561428/r/c9e840f5-7ea2-44d9-a53c-dad8a8334f4d?trace_id=c9e840f5-7ea2-44d9-a53c-dad8a8334f4d&start_time=2024-09-27T19%3A30%3A51.283102)를 비교해보세요.

지금까지 우리는 두 개의 서로 다른 스레드에서 몇 개의 체크포인트를 생성했습니다. 그런데 체크포인트에는 무엇이 저장될까요? 특정 설정에 대한 그래프 상태를 언제든지 확인하려면 `get_state(config)`를 호출하면 됩니다.
``` python
snapshot = graph.get_state(config)
snapshot
```
```
StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='8c1ca919-c553-4ebf-95d4-b59a2d61e078'), AIMessage(content="Hello Will! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to know or discuss?", additional_kwargs={}, response_metadata={'id': 'msg_01WTQebPhNwmMrmmWojJ9KXJ', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 405, 'output_tokens': 32}}, id='run-58587b77-8c82-41e6-8a90-d62c444a261d-0', usage_metadata={'input_tokens': 405, 'output_tokens': 32, 'total_tokens': 437}), HumanMessage(content='Remember my name?', additional_kwargs={}, response_metadata={}, id='daba7df6-ad75-4d6b-8057-745881cea1ca'), AIMessage(content="Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you'd like to talk about or any questions you have? I'm here to help with a wide range of topics or tasks.", additional_kwargs={}, response_metadata={'id': 'msg_01E41KitY74HpENRgXx94vag', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 444, 'output_tokens': 58}}, id='run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0', usage_metadata={'input_tokens': 444, 'output_tokens': 58, 'total_tokens': 502})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef7d06e-93e0-6acc-8004-f2ac846575d2'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content="Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you'd like to talk about or any questions you have? I'm here to help with a wide range of topics or tasks.", additional_kwargs={}, response_metadata={'id': 'msg_01E41KitY74HpENRgXx94vag', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 444, 'output_tokens': 58}}, id='run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0', usage_metadata={'input_tokens': 444, 'output_tokens': 58, 'total_tokens': 502})]}}, 'step': 4, 'parents': {}}, created_at='2024-09-27T19:30:10.820758+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef7d06e-859f-6206-8003-e1bd3c264b8f'}}, tasks=())
```
``` python
snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)
```
```
()
```

위 스냅샷에는 현재 상태의 값, 설정 그리고 다음에 처리할 노드 정보가 포함되어 있습니다. 이번 경우에는 그래프가 `END` 상테에 도달했으므로 `next`는 비어있습니다. 

Congratulations! 이제 여러분의 챗봇은 랭그래프의 체크포인팅 시스템 덕분에 세션 간에도 대화 상태를 유지할 수 있게 되었습니다. 이는 보다 자연스럽고 맥락을 이해하는 상호작용을 가능하게 해주며, LangGraph의 체크포인팅은 단순한 채팅 메모리보다 훨씬 더 표현력 있고 강력하고 복잡한 그래프 상태도 처리할 수 있습니다.

다음 파트에서는 챗봇을 진행하기 전에 지침이나 확인이 필요한 상황을 처리할 수 있도록 인간의 개입(Human Oversight)을 도입할 것입니다.

이번 섹션에서 만든 그래프를 다시 확인하고 싶다면 아래 코드 스니펫을 살펴보세요.
``` python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.set_entry_point("chatbot")
memory = MemorySaver()
graph = graph_builder.compile(checkpointer=memory)
```
