## Part 3: ì±—ë´‡ì— ë©”ëª¨ë¦¬ ì¶”ê°€í•˜ê¸°
ì±—ë´‡ì€ ì‚¬ìš©ì ì§ˆë¬¸ì— toolì„ ì´ìš©í•˜ì—¬ ë‹µí•  ìˆ˜ ìˆìœ¼ë‚˜, ì´ì „ì˜ ìƒí˜¸ì‘ìš©ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ì–µí•˜ì§€ ëª»í•©ë‹ˆë‹¤. ì´ê²ƒì€ ì¼ê´€ì„± ìˆëŠ” multi-turn ëŒ€í™”ë¥¼ ìˆ˜í–‰í•˜ëŠ” ëŠ¥ë ¥ì„ ì œí•œí•©ë‹ˆë‹¤.

ë­ê·¸ë˜í”„ëŠ” `persistent checkpointing`ì„ í†µí•´ ì´ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•  ë•Œ ì²´í¬í¬ì¸í„°ë¥¼ ì œê³µí•˜ê³ , ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•  ë•Œ `thread_id`ë¥¼ ì œê³µí•˜ë©´, LangGraphëŠ” ê° ë‹¨ê³„ ì´í›„ì— ìƒíƒœë¥¼ ìë™ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ë™ì¼í•œ `thread_id`ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ë‹¤ì‹œ í˜¸ì¶œí•˜ë©´, ê·¸ë˜í”„ëŠ” ì €ì¥ëœ ìƒíƒœë¥¼ ë¶ˆëŸ¬ì™€ ì±—ë´‡ì´ ì¤‘ë‹¨ëœ ì§€ì ë¶€í„° ë‹¤ì‹œ ì´ì–´ì„œ ëŒ€í™”ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

ë‹¨ìˆœí•œ ì±„íŒ… ë©”ëª¨ë¦¬ë³´ë‹¤ ë” íŒŒì›Œí’€í•œ `checkpointing`ì€ ì¡°ê¸ˆ ë’¤ì— ì‚´í´ë³¼ ê²ƒì´ë©°, ì˜¤ë¥˜ ë³µêµ¬, ì¸ê°„ì˜ ê²€í† ê°€ í¬í•¨ëœ ì›Œí¬í”Œë¡œìš°, ê³¼ê±° ìƒíƒœë¡œ ëŒì•„ê°€ëŠ” ìƒí˜¸ì‘ìš© ë“± ì–¸ì œë“ ì§€ ë³µì¡í•œ ìƒíƒœë¥¼ ì €ì¥í•˜ê³  ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. í•˜ì§€ë§Œ, ì•ì„œ ë‚˜ê°€ê¸° ì „ì— ìš°ì„  multi-turn ëŒ€í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê¸° ìœ„í•´ì„œ checkpointingì„ ì¶”ê°€í•´ë´…ì‹œë‹¤.

`MemorySaver` checkpointerë¥¼ ë§Œë“¤ì–´ ë´…ì‹œë‹¤.
``` python
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
```
API Reference: [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)

**Notice** ê°„í¸í•œ íŠœí† ë¦¬ì–¼ ì§„í–‰ì„ ìœ„í•´ ì¸ë©”ëª¨ë¦¬ ì²´í¬í¬ì¸í„°ë¥¼ ì‚¬ìš©ì¤‘ì…ë‹ˆë‹¤(ëª¨ë“  ê²ƒì„ ë©”ëª¨ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.). í”„ë¡œë•ì…˜ ì–´í”Œë¦¬ì¼€ì´ì…˜ì´ë¼ë©´, ì´ê²ƒì„ `SqliteSaver`ë‚˜ `PostgreSaver`ë¡œ ë°”ê¾¸ì–´ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì—°ê²°í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

ë‹¤ìŒì€ ê·¸ë˜í”„ë¥¼ ì •ì˜í•´ ë´…ì‹œë‹¤. ì´ë¯¸ `BasicToolNode`ë¥¼ ë§Œë“¤ì—ˆìœ¼ë‹ˆ, ìš°ë¦¬ëŠ” ê·¸ê²ƒì„ ë­ê·¸ë˜í”„ì˜ prebuiltëœ `ToolNode`ì™€ `tools_condition`ìœ¼ë¡œ ë³€ê²½í•˜ê³ , ì´ë“¤ì€ APIë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ëŠ” ë“± ìœ ìš©í•œ ê¸°ëŠ¥ë“¤ì„ ì œê³µí•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê·¸ ì™¸ì—ëŠ” ì•„ë˜ ë‚´ìš©ì€ ëª¨ë‘ Part2ì—ì„œ ë³µì‚¬í•´ì˜¨ ê²ƒë“¤ì…ë‹ˆë‹¤.
``` python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
# Any time a tool is called, we return to the chatbot to decide the next step
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
```
API Reference: [ChatAnthropic](https://python.langchain.com/api_reference/anthropic/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html) | [TavilySearchResults](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html) | [BaseMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.base.BaseMessage.html)
| [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode)
| [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.tools_condition)


ë§ˆì¹¨ë‚´, checkpointerê°€ ì¶”ê°€ëœ ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•˜ì˜€ìŠµë‹ˆë‹¤.
``` python
graph = graph_builder.compile(checkpointer=memory)
```
ê·¸ë˜í”„ì˜ ì—°ê²° êµ¬ì¡°ëŠ” Part2ì™€ ê°™ìŠµë‹ˆë‹¤. ê° ë…¸ë“œë¥¼ ê±°ì¹˜ë©° ê·¸ë˜í”„ê°€ ì‘ë™í•˜ëŠ” ë™ì•ˆ ìƒíƒœ(State)ë¥¼ ì²´í¬í¬ì¸íŠ¸ë¡œ ì €ì¥í•˜ëŠ” ê²ƒë¿ì…ë‹ˆë‹¤.
``` python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # This requires some extra dependencies and is optional
    pass
```

![Image](https://github.com/user-attachments/assets/7cf31980-9629-4e19-a6f9-ca2457b1af8c)

ì´ì œ, ë§Œë“  ë´‡ê³¼ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ë¨¼ì €, ì´ ëŒ€í™”ì˜ keyë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤ë ˆë“œë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.
``` python
config = {"configurable": {"thread_id": "1"}}
```
ê·¸ ë‹¤ìŒ, ì±—ë´‡ì„ í˜¸ì¶œí•˜ì„¸ìš”.
``` python
user_input = "Hi there! My name is Will."

# The config is the **second positional argument** to stream() or invoke()!
events = graph.stream(
    {"messages": [{"role": "user", "content": user_input}]},
    config, # <--
    stream_mode="values",
)
for event in events:
    event["messages"][-1].pretty_print()
```
```
================================[1m Human Message [0m=================================

Hi there! My name is Will.
==================================[1m Ai Message [0m==================================

Hello Will! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to know or discuss?
```

**Note**: êµ¬ì„±ì€ ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•  ë•Œ ë‘ ë²ˆì§¸ ìœ„ì¹˜ ì¸ìë¡œ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ì ì€, ì´ê²ƒì´ ê·¸ë˜í”„ ì…ë ¥ê°’(`{'messages': []}`) ì•ˆì— ì¤‘ì²©ë˜ì–´ ìˆì§€ ì•Šë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

ë’¤ì´ì–´ ë‹¤ìŒ ì§ˆë¬¸ì„ í•´ë´…ì‹œë‹¤: ë‹¹ì‹ ì˜ ì´ë¦„ì„ ê¸°ì–µí•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.
``` python
user_input = "Remember my name?"

# The config is the **second positional argument** to stream() or invoke()!
events = graph.stream(
    {"messages": [{"role": "user", "content": user_input}]},
    config,
    stream_mode="values",
)
for event in events:
    event["messages"][-1].pretty_print()
```
```
================================[1m Human Message [0m=================================

Remember my name?
==================================[1m Ai Message [0m==================================

Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you'd like to talk about or any questions you have? I'm here to help with a wide range of topics or tasks.
```

**Notice** ë©”ëª¨ë¦¬ë¥¼ ìœ„í•´ ì™¸ë¶€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ìˆë‹¤ëŠ” ì ì— ì£¼ëª©í•˜ì„¸ìš”. ì´ ëª¨ë“  ê²ƒì€ ì²´í¬í¬ì¸í„°ê°€ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤! ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚¬ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ì´ [LangSmith](https://smith.langchain.com/public/29ba22b5-6d40-4fbe-8d27-b369e3329c84/r) ì¶”ì ì—ì„œ ì „ì²´ ì‹¤í–‰ ê³¼ì •ì„ ì‚´í´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![Image](https://github.com/user-attachments/assets/383f8c3a-3a48-403b-9547-5be1e329b991)

ì €ë¥¼ ëª»ë¯¿ìœ¼ì‹œê² ë‚˜ìš”? ê·¸ë ‡ë‹¤ë©´ ë‹¤ë¥¸ êµ¬ì„±ì„ ì‹œë„í•´ë³´ì„¸ìš”.
``` python
# The only difference is we change the `thread_id` here to "2" instead of "1"
events = graph.stream(
    {"messages": [{"role": "user", "content": user_input}]},
    {"configurable": {"thread_id": "2"}}, # 1 -> 2ë¡œ ìŠ¤ë ˆë“œ ë²ˆí˜¸ ë³€ê²½
    stream_mode="values",
)
for event in events:
    event["messages"][-1].pretty_print()
```
```
================================[1m Human Message [0m=================================

Remember my name?
==================================[1m Ai Message [0m==================================

I apologize, but I don't have any previous context or memory of your name. As an AI assistant, I don't retain information from past conversations. Each interaction starts fresh. Could you please tell me your name so I can address you properly in this conversation?
```

**Notice** configì˜ `thread_id`ë§Œ ë°”ë€Œì—ˆìŠµë‹ˆë‹¤. [LangSmith trace](https://smith.langchain.com/public/51a62351-2f0a-4058-91cc-9996c5561428/r/c9e840f5-7ea2-44d9-a53c-dad8a8334f4d?trace_id=c9e840f5-7ea2-44d9-a53c-dad8a8334f4d&start_time=2024-09-27T19%3A30%3A51.283102)ë¥¼ ë¹„êµí•´ë³´ì„¸ìš”.

ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ëŠ” ë‘ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ìŠ¤ë ˆë“œì—ì„œ ëª‡ ê°œì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ì²´í¬í¬ì¸íŠ¸ì—ëŠ” ë¬´ì—‡ì´ ì €ì¥ë ê¹Œìš”? íŠ¹ì • ì„¤ì •ì— ëŒ€í•œ ê·¸ë˜í”„ ìƒíƒœë¥¼ ì–¸ì œë“ ì§€ í™•ì¸í•˜ë ¤ë©´ `get_state(config)`ë¥¼ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤.
``` python
snapshot = graph.get_state(config)
snapshot
```
```
StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='8c1ca919-c553-4ebf-95d4-b59a2d61e078'), AIMessage(content="Hello Will! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to know or discuss?", additional_kwargs={}, response_metadata={'id': 'msg_01WTQebPhNwmMrmmWojJ9KXJ', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 405, 'output_tokens': 32}}, id='run-58587b77-8c82-41e6-8a90-d62c444a261d-0', usage_metadata={'input_tokens': 405, 'output_tokens': 32, 'total_tokens': 437}), HumanMessage(content='Remember my name?', additional_kwargs={}, response_metadata={}, id='daba7df6-ad75-4d6b-8057-745881cea1ca'), AIMessage(content="Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you'd like to talk about or any questions you have? I'm here to help with a wide range of topics or tasks.", additional_kwargs={}, response_metadata={'id': 'msg_01E41KitY74HpENRgXx94vag', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 444, 'output_tokens': 58}}, id='run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0', usage_metadata={'input_tokens': 444, 'output_tokens': 58, 'total_tokens': 502})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef7d06e-93e0-6acc-8004-f2ac846575d2'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content="Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you'd like to talk about or any questions you have? I'm here to help with a wide range of topics or tasks.", additional_kwargs={}, response_metadata={'id': 'msg_01E41KitY74HpENRgXx94vag', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 444, 'output_tokens': 58}}, id='run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0', usage_metadata={'input_tokens': 444, 'output_tokens': 58, 'total_tokens': 502})]}}, 'step': 4, 'parents': {}}, created_at='2024-09-27T19:30:10.820758+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef7d06e-859f-6206-8003-e1bd3c264b8f'}}, tasks=())
```
``` python
snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)
```
```
()
```

ìœ„ ìŠ¤ëƒ…ìƒ·ì—ëŠ” í˜„ì¬ ìƒíƒœì˜ ê°’, ì„¤ì • ê·¸ë¦¬ê³  ë‹¤ìŒì— ì²˜ë¦¬í•  ë…¸ë“œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ ê²½ìš°ì—ëŠ” ê·¸ë˜í”„ê°€ `END` ìƒí…Œì— ë„ë‹¬í–ˆìœ¼ë¯€ë¡œ `next`ëŠ” ë¹„ì–´ìˆìŠµë‹ˆë‹¤. 

Congratulations! ì´ì œ ì—¬ëŸ¬ë¶„ì˜ ì±—ë´‡ì€ ë­ê·¸ë˜í”„ì˜ ì²´í¬í¬ì¸íŒ… ì‹œìŠ¤í…œ ë•ë¶„ì— ì„¸ì…˜ ê°„ì—ë„ ëŒ€í™” ìƒíƒœë¥¼ ìœ ì§€í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë³´ë‹¤ ìì—°ìŠ¤ëŸ½ê³  ë§¥ë½ì„ ì´í•´í•˜ëŠ” ìƒí˜¸ì‘ìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•´ì£¼ë©°, LangGraphì˜ ì²´í¬í¬ì¸íŒ…ì€ ë‹¨ìˆœí•œ ì±„íŒ… ë©”ëª¨ë¦¬ë³´ë‹¤ í›¨ì”¬ ë” í‘œí˜„ë ¥ ìˆê³  ê°•ë ¥í•˜ê³  ë³µì¡í•œ ê·¸ë˜í”„ ìƒíƒœë„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ íŒŒíŠ¸ì—ì„œëŠ” ì±—ë´‡ì„ ì§„í–‰í•˜ê¸° ì „ì— ì§€ì¹¨ì´ë‚˜ í™•ì¸ì´ í•„ìš”í•œ ìƒí™©ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì¸ê°„ì˜ ê°œì…(Human Oversight)ì„ ë„ì…í•  ê²ƒì…ë‹ˆë‹¤.

ì´ë²ˆ ì„¹ì…˜ì—ì„œ ë§Œë“  ê·¸ë˜í”„ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì½”ë“œ ìŠ¤ë‹ˆí«ì„ ì‚´í´ë³´ì„¸ìš”.
``` python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-5-sonnet-20240620")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.set_entry_point("chatbot")
memory = MemorySaver()
graph = graph_builder.compile(checkpointer=memory)
```
