## Part 3: 챗봇에 메모리 추가하기
챗봇은 사용자 질문에 tool을 이용하여 답할 수 있으나, 이전의 상호작용의 컨텍스트를 기억하지 못합니다. 이것은 일관성 있는 multi-turn 대화를 수행하는 능력을 제한합니다.

랭그래프는 `persistent checkpointing`을 통해 이 문제를 해결할 수 있습니다. 그래프를 컴파일할 때 체크포인터를 제공하고, 그래프를 호출할 때 `thread_id`를 제공하면, LangGraph는 각 단계 이후에 상태를 자동으로 저장합니다. 동일한 `thread_id`를 사용하여 그래프를 다시 호출하면, 그래프는 저장된 상태를 불러와 챗봇이 중단된 지점부터 다시 이어서 대화를 진행할 수 있습니다. 

단순한 채팅 메모리보다 더 파워풀한 `checkpointing`은 조금 뒤에 살펴볼 것이며, 오류 복구, 인간의 검토가 포함된 워크플로우, 과거 상태로 돌아가는 상호작용 등 언제든지 복잡한 상태를 저장하고 다시 불러올 수 있게 해줍니다. 하지만, 앞서 나가기 전에 우선 multi-turn 대화를 가능하게 하기 위해서 checkpointing을 추가해봅시다.

`MemorySaver` checkpointer를 만들어 봅시다.
``` python
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
```
API Reference: [MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.MemorySaver)
